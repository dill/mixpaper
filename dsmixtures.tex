\documentclass[10pt]{article}

% amsmath package, useful for mathematical formulas
\usepackage{amsmath}
% amssymb package, useful for mathematical symbols
\usepackage{amssymb}

% graphicx package, useful for including eps and pdf graphics
% include graphics with the command %\includegraphics
\usepackage{graphicx}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

\usepackage{color} 

% Use doublespacing - comment out for single spacing
%\usepackage{setspace} 
%\doublespacing


% Text layout
\topmargin 0.0cm
\oddsidemargin 0.5cm
\evensidemargin 0.5cm
\textwidth 16cm 
\textheight 21cm

% Bold the 'Figure #' in the caption and separate it with a period
% Captions will be left justified
\usepackage[labelfont=bf,labelsep=period,justification=raggedright]{caption}

% Use the PLoS provided bibtex style
\bibliographystyle{plos2009}

% Remove brackets from numbering in List of References
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother


% Leave date blank
\date{}

\pagestyle{myheadings}
%% ** EDIT HERE **
%\usepackage{bm}

%% ** EDIT HERE **
%% PLEASE INCLUDE ALL MACROS BELOW
\renewcommand\citemid{ }
%% END MACROS SECTION

\begin{document}

% Title must be 150 characters or less
\begin{flushleft}
{\Large
\textbf{Mixture models for distance sampling detection functions}
}
% Insert Author names, affiliations and corresponding author email.
\\
David L. Miller$^{1,\ast}$,
Len Thomas$^{1}$
\\
\bf{1} School of Mathematics and Statistics, and Centre for Research into Ecological and Environmental Modelling, University of St Andrews, St Andrews KY16 9LZ, Scotland
\\
$\ast$ E-mail: dave@ninepointeightone.net
\end{flushleft}

% Please keep the abstract between 250 and 300 words
\section*{Abstract}

We present a new class of models for the detection function in distance sampling surveys of wildlife populations, based on finite mixtures of simple parametric key functions such as the half-normal. The models share many of the features of the widely-used ``key function plus series adjustment'' (K+A) formulation: they are flexible, produce plausible shapes with a small number of parameters, allow incorporation of covariates in addition to distance and can be fitted using maximum likelihood. One important advantage over the K+A approach is that the mixtures are automatically monotonic non-increasing and non-negative, so constrained optimization is not required to ensure distance sampling assumptions are honoured. We compare the mixture formulation to the K+A approach using simulations to evaluate its applicability in a wide set of challenging situations. We also re-analyze four previously problematic real-world case studies.  We find mixtures outperform K+A methods in many cases, particularly spiked line transect data (i.e., where detectability drops rapidly at small distances) and larger sample sizes.  We recommend that current standard model selection methods for distance sampling detection functions are extended to include mixture models in the candidate set.


%\begin{keyword}
%Finite mixture; Line transect sampling; Monotonicity constraint; Multiple covariate distance sampling; Point transect sampling.
%\end{keyword}

\section*{Introduction}

Distance sampling \cite{Buckland:2001vm,Buckland:2004ts} is a suite of methods for estimating the size or density of biological populations.  There are two main variants: line and point transects. In both, an observer visits a randomly-located set of transect lines or points and records the distance, $y$, from the transect to each object of interest (i.e., animals or plants of the target species) that is detected within some truncation distance $w$.  Not all objects within $w$ are assumed to be detected; instead the observed distances are used to estimate the parameter vector, $\boldsymbol{\theta}$, of a detection function model, $g(y;\boldsymbol{\theta})$, which describes how the probability of detection declines with increasing distance.  An assumption of the conventional method is that $g(0;\boldsymbol{\theta})=1$. Given an estimate of $\boldsymbol{\theta}$, it is straightforward to estimate population size or density (see below).

A key part of distance sampling, therefore, is specification of the detection function model. Buckland et al. (Chapter 2) \cite{Buckland:2001vm} provide a set of criteria for judging the utility of candidate model classes. Detection function models should be:
\begin{enumerate}
\item flexible, so that they can take a wide variety of shapes;
\item efficient, in the sense that many plausible shapes can be represented using few parameters;
\item flat at zero distance (i.e., $g'(0;\boldsymbol{\theta})=0$), indicating that objects in the immediate vicinity of the observer are equally detectable; and,
\item monotonic non-increasing with increasing distance (i.e., $g'(y;\boldsymbol{\theta}) \leq 0$ for $0<y\leq w$), as it is typically unrealistic for objects to become more detectable with increasing distance.
\end{enumerate}
The semiparametric ``key function plus series adjustment'' (K+A) modelling approach developed by Buckland \cite{Buckland:1992wy} has become by far the most popular in practice, partly due to its inclusion in the industry-standard distance sampling analysis software Distance \cite{Thomas:2010cf} and the R \cite{Team:2013wf} package mrds \cite{mrds} (available on the Comprehensive R Archive Network, CRAN; http://cran.r- project.org/).  However, as we demonstrate below, the approach has some drawbacks; in particular, although it meets criteria 1-3, it does not necessarily meet the 4$^\text{th}$.  Our purpose in this article is to propose an alternative class of models, based on mixtures, that meet all 4 criteria and to evaluate its utility.  

The approach of Buckland \cite{Buckland:1992wy} was extended by Marques and Buckland \cite{Marques:2003vb} to allow covariates in addition to distance to be included in the detection function, and, for maximum generality, it is this K+A formulation that we describe here.  The detection function is thus denoted $g(y, \mathbf{z};\boldsymbol{\theta})$ where $\mathbf{z}$ is an observation-specific vector of covariates; the formulation of Buckland \cite{Buckland:1992wy} is simply a special case of this model where there are no additional covariates. 

In Marques and Buckland \cite{Marques:2003vb}, the detection function is modelled as a parametric key function $k$ and series expansion $s$ of even functions (known as \textit{adjustment terms}) with some parameters $\boldsymbol{\theta}$. $g$ is then written as:
\begin{equation*}
g(y, \mathbf{z}; \boldsymbol{\theta}) = \frac{k(y, \mathbf{z}; \boldsymbol{\theta}) \{1+s(y, \mathbf{z}; \boldsymbol{\theta})\}}{k(0, \mathbf{z}; \boldsymbol{\theta}) \{1+s(0, \mathbf{z}; \boldsymbol{\theta})\}},
\end{equation*}
where $k$ may be a half-normal, hazard-rate or uniform function and $s$ may be zero (i.e., there are no adjustment terms), cosine, simple even polynomial or Hermite polynomial series (though note a uniform detection function may not include covariates). The denominator ensures that detection function evaluates to 1 at zero distance (i.e., $g(0, \mathbf{z};\boldsymbol{\theta})=1$). Model parameters are estimated using maximum likelihood.  The recommended strategy for most situations is to choose a small set of key function and adjustment combinations, and for each combination to choose the number of adjustment terms using forward selection, i.e., start with no adjustment terms and fit an increasing number of terms, stopping when the Akaike Information Criterion (AIC) fails to decrease \cite{Thomas:2010cf}. The combination with the lowest AIC is then selected as the best model. This strategy works well in practice in many cases: the key functions cover a range of realistic shapes for the detection function, so that often zero or one adjustments are sufficient to provide a good fit to the data, resulting in flexible and yet efficient estimation. 

The resulting detection functions are capable of being flat at zero distance and the key functions are non-increasing. However, adding adjustment terms can result in non-monotonic functions. Further, when both covariates and adjustments are included in the model the range of the resulting detection function may not be [0,1]. When there are no additional covariates, one solution is to use constrained maximization, e.g. taking $M$ equally spaced distances $y_1=0, \ldots , y_{M}=w$ and ensuring that $g(y_i;\boldsymbol{\hat{\theta}})\geq g(y_{i+1}; \boldsymbol{\hat{\theta}})$ and that $g(y_{i+1};\boldsymbol{\hat{\theta}})\geq 0$ for $i=1,\ldots,M-1$. In Distance this constraint is implemented using the NLPQL routine \cite{Schittkowski:1986wj} and in the R package mrds, the SOLNP algorithm \cite{Ye:1987wt} is used.

A constrained optimisation solution presents a number of problems. First, constrained maximization is a more complex optimization problem than unconstrained maximization; this means that in practice optimization algorithms may fail to find the constrained maximum.  Second, constrained maximum likelihood estimates do not have the same appealing properties as their unconstrained relatives -- for example the usual estimator of the standard error of the parameters (square root of the inverse of the information matrix) can be biased.  Third, constraints can only be applied at a finite number of points ($M=10$ is used in Distance and $M=20$ in mrds by default), which can lead to the constraint points missing non-monotonic parts of the function. Though increasing the number of points is an option, this incurs additional computational cost. An example of constrained maximisation failing is shown in the left panel of Figure \ref{fig1}. Finally, it is not clear how to implement the constraints in the case where there are additional covariates, particularly continuous covariates. One computationally expensive option would be to apply the constraints at every observed covariate combination (at present both Distance and mrds use unconstrained optimization when additional covariates are in the model). The central and right panels of Figure \ref{fig1} from Pike et al. \cite{Pike:2003ug} show an example of covariate models fitted using unconstrained optimisation: a strongly non-monotonic function has been fitted for some covariate values. Detection probability estimates outside the range $[0,1]$ are sometimes encountered during maximization when models include covariates. Given the above issues, it seems appealing to use a formulation that guarantees monotonicity from the outset.

Mixture models have been applied in the capture-recapture literature \cite{Pledger:2000tc, Dorazio:2003uf, Pledger:2005wy, Morgan:2008wy}. The main utility of mixture models in capture-recapture is in better accounting for between-individual heterogeneity, which can cause severe bias if unmodelled \cite{Link:2003wo}. Unmodelled heterogeneity is not generally considered an issue in distance sampling, provided that detection at zero distance is certain, heterogeneity is not extreme and a flexible detection function model is used \cite[Section 11.12]{Buckland:2004ts}. Mixture models offer the potential for flexible modelling since the individual parts of the mixture model (the \textit{mixture components}) can be combined to obtain flexible detection functions, and provided each component is monotonic non-increasing, the resulting combination will also be monotonic non-increasing. In addition, mixture models are potentially well suited to deal with highly heterogeneous detection probabilities, where some part of the population is only observable at close distances while others are readily detected almost regardless of distance (for example bird species where males are more vocal than females). Such a situation results in a ``spiked'' detection function with a long flat tail -- Figure \ref{fig1} shows relatively mild examples. In a mixture model, different parts of the sample could be represented by different components, providing a good fit to spiked data and an appealing conceptual explanation for the underlying data.

Here we introduce a new class of distance sampling detection function models, based on mixtures of simple parametric key functions.  In the next section, we describe the models.  We then illustrate their use and explore their performance by applying them to simulated data, and to real data from a number of studies. We also compare results with those obtained from the current standard K+A approach, and by using a combined approach where both the mixtures and K+A models are fitted and a final model selected using AIC. An R package, mmds \cite{mmds} (Mixture Model Distance Sampling), implementing the methods is available from CRAN.

\section*{Methods}

\subsection*{Finite mixture model detection functions: Formulation}

Denoting the detection function as $g$, we consider a sum of $J$ mixture components $g_j$, scaled by some mixture proportions $\phi_j$:
\begin{equation*}
g(y,\mathbf{z}; \boldsymbol{\theta}, \boldsymbol{\phi}) = \sum_{j=1}^J \phi_j g_j(y,\mathbf{z}; \boldsymbol{\theta}_j),
\end{equation*}
where $\sum_{j=1}^J \phi_j = 1$. The distance is denoted $y$, the $\boldsymbol{\theta}_j$s are vectors of parameters for function $g_j$, $\boldsymbol{\theta}$ is a vector of all of the $\boldsymbol{\theta}_j$s, $\boldsymbol{\phi}$ is a $J$-vector of all of the $\phi_j$s, and $\mathbf{z}$ is a $K$-vector of the associated covariates.  

Although other monotonic functions such as hazard-rate could be chosen, and the $g_j$s need not all have the same form, here we let the $g_j$s be half-normal functions:
\begin{equation*}
g(y,\mathbf{z}; \boldsymbol{\theta}, \boldsymbol{\phi}) = \sum_{j=1}^J \phi_j \exp \Big( - \frac{y^2}{2\sigma_j(\mathbf{z})^2} \Big).
\end{equation*}
We assume that each mixture component has a different scale but that the covariates affect the scale parameters in the same way (though other, more complex, models may be possible).

Covariates are included as in Marques and Buckland \cite{Marques:2003vb}, by decomposing the scale parameter $\sigma$ (see also Marques et al. \cite{Marques:2007vm}).  Using $i$ to subscript each observation, our formulation for the scale parameter $\sigma_{ij}$, is
\begin{equation*}
\sigma_{ij} = \exp( \beta_{0j} + \sum_{k=1}^K \beta_k z_{ik}),
\end{equation*}
where $z_{ik}$ is the $k^\text{th}$ covariate for the $i^\text{th}$ observation. In this case $\boldsymbol{\theta}$ will contain the $\beta_{0j}$s and $\beta_k$s.

We can write the pdf of the observed distances conditional on the observed covariates as\cite{Buckland:2004ts}:
\begin{equation*}
f(y \vert \mathbf{z}; \boldsymbol{\theta}, \boldsymbol{\phi}) = \frac{\pi(y)g(y, \mathbf{z}; \boldsymbol{\theta}, \boldsymbol{\phi})}{\int_0^w \pi(t)g(t, \mathbf{z}; \boldsymbol{\theta}, \boldsymbol{\phi}) \text{d}t}.
\end{equation*}
where $\pi(y)$ is the pdf of object distances (observed and unobserved). The likelihood can then be formed by taking product of these pdfs over the $n$ observations.  The specific form of the likelihood differs between line and point transects, because sampler geometry means that the form of $\pi(y)$ is different for lines and points.  For line transects, with random line placement, we expect an equal number of objects at all distances from the line, and hence $\pi(y)=1/w$ (where $w$ is again the truncation distance).  The likelihood is then given by:
\begin{align*}
\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi}; \mathbf{y} \vert \mathbf{z}_1, \ldots, \mathbf{z}_n) &= \prod_{i=1}^n f(y_i \vert \mathbf{z}_i; \boldsymbol{\theta},\boldsymbol{\phi})\\
&= \prod_{i=1}^n \frac{g(y_i,\mathbf{z}_i; \boldsymbol{\theta},\boldsymbol{\phi})}{\mu_i(\mathbf{z}_i)}\\
&= \prod_{i=1}^n \frac{\sum_{j=1}^J \phi_j g_j(y_i,\mathbf{z}_i; \boldsymbol{\theta}_j)}{\mu_i(\mathbf{z}_i)}
\end{align*}
where $\mu_i(\mathbf{z}_i)$, the \textit{effective strip width} (for covariate combination $\mathbf{z}_i$), is given by:
\begin{equation}
\label{e:esw}
\mu_{i}(\mathbf{z}_i) = \sum_{j=1}^J \phi_j \int_0^w  g_j(y,\mathbf{z}_i; \boldsymbol{\theta}_j) \text{d}y.
\end{equation}
For point transects, with random point placement, the expected number of objects increases with increasing distance from the point, and hence $\pi(y)=2y/w^2$, giving
\begin{align*}
\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi}; \mathbf{y}  \vert \mathbf{z}_1, \ldots, \mathbf{z}_n) &= \prod_{i=1}^n f(y_i \vert \mathbf{z}_i; \boldsymbol{\theta},\boldsymbol{\phi})\\
&= \prod_{i=1}^n \frac{2 \pi y_i g(y_i,\mathbf{z}_i; \boldsymbol{\theta},\boldsymbol{\phi})}{\nu_i}\\
&= \prod_{i=1}^n \frac{2 \pi y_i \sum_{j=1}^J \phi_j g_j(y_i,\mathbf{z}_i; \boldsymbol{\theta}_j)}{\nu_i}
\end{align*}
where $\nu_i$, the \textit{effective area of detection} (for covariate combination $\mathbf{z}_i$), is defined as:
\begin{equation}
\label{e:ead}
\nu_i = 2\pi \sum_{j=1}^J \phi_j \int_0^w  y g_j(y,\mathbf{z}_i; \boldsymbol{\theta}_j) \text{d}y.
\end{equation}

For both line and point transects, parameters are estimated using maximum likelihood. Practicalities associated with this maximization, along with analytic derivatives of the likelihood are described in Appendix S1 and Text S1.  The best number of mixture components to use for inference can be determined using standard model selection techniques, such as Akaike's Information Criterion (AIC), and goodness-of-fit of fitted models can be assessed just as for K+A models using, for example quantile-quantile plots and Kolmogorov-Smironov tests (see Buckland et al. \cite{Buckland:2004ts}, Section 11.11).

In this article, we assume the distance data are in the form of ``exact'' object-transect distances; alternatively, distances can be grouped into intervals, with pre-defined cutpoints (e.g., 0-10m, 10-20m, etc.), so that the data are the distance interval of each observation.  In this case, a multinomial likelihood is obtained (see, e.g. Buckland et al. \cite{Buckland:2001vm}, Section 3.3.2).  Also, in some cases (e.g., some aerial surveys), objects below a defined distance are not counted -- so-called ``left truncation'' \cite[Section 4.3.2]{Buckland:2001vm}.  The likelihood is readily amended to account for this, by changing the lower limit of integration in equation \eqref{e:esw} or \eqref{e:ead}.

\subsection*{Estimating population size}

Population size can be estimated using the Horvitz-Thompson-like estimator \cite{Marques:2003vb}:
\begin{equation}
\label{e:popsize}
\hat{N}=\frac{A}{a}\sum_{i=1}^n \frac{1}{\hat {p}_i}
\end{equation}
where $A$ is the area of the study region for which population size is being estimated, $a$ is the size of the sampled area, and $p_i$ is the probability of the $i^\text{th}$ observation being detected given it is within the sampled area.  For line transects, $a=2wL$ where $L$ is the total line length, and 
\begin{equation*}
\hat{p}_i = \frac{1}{w} \sum_{j=1}^J \hat{\phi}_j \int_0^w  g_j(y,\mathbf{z}_{i}; \boldsymbol{\hat{\theta}}_j) \text{d}y.
\end{equation*}
For point transects, $a=\pi w^2 k$ where $k$ is the number of points, and 
\begin{equation*}
\hat{p}_i = \frac{2\pi}{w^2} \sum_{j=1}^J \hat{\phi}_j \int_0^w  y g_j(y,\mathbf{z}_{i}; \boldsymbol{\hat{\theta}
}_j) \text{d}y.
\end{equation*}
A standard summary statistic is the average detection probability for an animal within the sampled area, $\hat{P_a}$, which is given by:
\begin{equation*}
\hat{P_a} = n/\hat{N}.
\end{equation*}
Estimators for the variances of $\hat{N}$ and $\hat{P_a}$ are given in Text S2.

\subsection*{Examples}

\textbf{Simulated data.} Extensive simulations were carried out to investigate performance (in terms of the accuracy of estimation of $P_a$) when the true detection function model is not known to the estimation procedure. 
 Buckland et al. \cite{Buckland:2001vm} show that accurate results are readily obtained in situations where there is a wide ``shoulder'' of high detection probability at small and medium distances: in such situations, the dependence on having a good detection function model is only slight.  Hence, we focus here on a variety of more challenging scenarios.

Each simulation involved generating 200 replicate datasets from a specified detection function model (assuming the entire study area was included within the surveyed transects, i.e., $A=a$ in equation (\ref{e:popsize}), and a truncation distance of $w=1$), fitting each dataset with a range of mixture and key series plus series adjustment (K+A) models, and in each case recording estimated parameter values and abundance from the model with the lowest AIC in each of: mixture models, K+A models, and both combined.  Mixture models with 1-, 2-, and 3-point half-normal components were fitted to the data along with two K+A models: half-normal plus cosine adjustments and hazard rate plus simple polynomial adjustments, both with monotonicity constraints implemented as described above and with a maximum of 3 adjustments. Mixture models and K+A models were fitted using the R packages mmds (version 1.1) and Distance \cite{Distance} (a simplified interface to mrds; version 0.6.1) respectively, both written by the authors.

Fourteen different simulation scenarios were investigated, in five groups, as described below and illustrated in Figure \ref{sim-detfcts}, one line per group. True parameter values and summary statistics are given in Appendix S2.  For each scenario, a simulation was performed at each of five sample sizes (number of observations, $n$): 30 (low), 60 (recommended minimum for line transects \cite{Buckland:2001vm}), 120 (adequate), 480 (large) and 960 (very large).  We anticipated performance would depend upon sample size, because: the methods are likelihood-based and hence only asymptotically unbiased even if the correct model is fitted; the use of AIC to select model complexity meant that more flexible (and hence accurate) models could be expected to be selected given larger sample sizes. Mixture models are ``parameter hungry'' compared with K+A models, in the sense that each additional mixture component requires 2 extra parameters, while each additional adjustment term requires only one and hence, given the use of AIC for model selection, the relative performance of the two approaches may change at different sample sizes. 

\textit{Group A. Line transect with 2-point half-normal mixture detection functions.} Four scenarios were tested, representing a range of potentially challenging detection functions.  Scenarios A1 and A2 both have mixture components with quite different scale parameters, but in A1 the majority of data come from the less detectable component while in A2 it comes from the more detectable component.  A3 tests the behaviour of the models when the scale parameter of one of the mixture components is very large relative to the truncation distance. A4 has a large spike (i.e., a sharp decline in detectability at small distances), which is similar to some of the data we analyse in the case studies, below.

\textit{Group B. Point transect with detection functions as in the previous scenario.} The geometry of point transect sampling means there are few animals close to the point relative to those at larger distances. Hence, for a given sample size of observations, there are far fewer at small distances than for line transects, making it harder to accurately model the detection function in the critical region close to the point.  We therefore anticipate that performance will be worse for point transects. For this group, Figure \ref{sim-detfcts} shows pdfs of the observed distances.

\textit{Group C. Line transect with 3-point half-normal detection functions.} Two scenarios were tested. C1 has a detection function much like A2, enabling us to investigate the efficacy of model selection (i.e., we expect a 2-point mixture to be selected and to produce good results). C2 is a more complex shape that could only be created using a 3-point mixture; it has the added complication (as with A3) that one of the components has a large scale parameter relative to truncation distance.

\textit{Group D. Line transect with 2-point half-normal detection functions, and additional covariates.}  We used covariate models to test two aspects of model robustness. In the first, we assumed the covariate values were observed, and included covariate models in the candidate set, along with distance-only models. Our prediction was that (at large sample sizes at least) covariate models would be selected and estimation of $P_a$ unbiased.  In the second, we assumed the covariate values were not observed, and hence covariate models were not in the candidate set.  Our expectation was that (at larger sample sizes) more complex mixture distributions would be selected to compensate for the additional unobserved complexity, and that estimation of $P_a$ would not be greatly affected.  Two scenarios were tested.  D1 had a binary factor covariate, with half the observations having one covariate value and half the other.  D2 had a continuous covariate, whose fixed values were generated from a standard normal distribution function.  Detection functions are shown in the fourth row of Figure \ref{sim-detfcts}, along with the marginal detection functions for the levels/quartiles of the covariates. Note that, for the unobserved covariate models, D1 is equivalent to a 4-point mixture, while D2 is equivalent to a 2-point continuous mixture; neither of these models were in the candidate model set.  In the case of the K+A models, and in line with common practice, if covariates were included in the models then adjustment terms were not.

\textit{Group E. Line transect with other detection functions.} The above models all use the same functional form for $g_j$ in generation and fitting.  Here we tested the model robustness using two alternative data generating functions, not in the candidate model set (see Appendix S2 for formulation).  E1 used an exponential power series function (a generalization of the half-normal function with an additional shape parameter); E2 used a mixture of two hazard-rate functions, giving a shape that may be difficult to fit with half-normal models.

\textbf{Case studies.} The first two case studies return to the datasets depicted in Figure \ref{fig1}, and demonstrate how the mixture formulation solves the issue of non-monotonic detection functions.  The first case study also includes two other species, illustrating how the new approach can fit real data as well as, or better than, the K+A approach. The second case study gives an example of when covariate models can cause non-monotonicity.  The third case study demonstrates modelling of spiked line transect data, while the fourth gives a point transect example, with covariates.

\textbf{Case study: British Columbia marine mammals.} Williams and Thomas \cite{Williams:2007tc} used a data from a line transect survey to study several species of marine mammal off the coast of British Columbia, Canada. Here, we investigate three species: harbour seal (\textit{Phoca vitulina}) in water (the data also contained observations of hauled-out animals, which were not analysed here), harbour porpoise (\textit{Phocoena phocoena}) and humpback whale (\textit{Megaptera novaeangliae}). Truncation distances were set at 500m, 500m and 2000m for each species respectively, giving sample sizes of 232, 59, and 70 observations. 

\textbf{Case study: Long-finned pilot whales.} Pike et al. \cite{Pike:2003ug} analyzed observations of 84 pods of long-finned pilot whales (\textit{Globicephala melas}), sighted as part of a line transect survey, the North Atlantic Sightings Survey NASS-2001. The Beaufort sea state was recorded as a covariate during the survey and enters the authors' model as either a continuous variable, or a factor with 2 levels (0-1, $2+$), 3 levels (0-1, 2, $3+$), or 5 levels (0, 1, 2, 3, 4, with one value of 3.5 coded as 4).
  
\textbf{Case study: Wood ants.} Borkin et al. \cite{Borkin:2012vj} analyse data on two species of wood ant (\textit{Formica aquilonia} and \textit{Formica lugubris}) collected during a line transect survey of the Abernethy Forest, Scotland, in 2003. The number of nests sighted was 150, with the farthest being 72.04m from the transect, although 45\% of the nest sightings lay within 4m of the line. As part of their analysis, several different truncation distances were used. Larger truncation distances led to a large variance in the encounter rate estimates and hence in overall abundance estimates \cite{Borkin:2012vj}. This is due to the spike caused by the large number of detections close to the line (see Figure S4). As well as distances, three covariates were recorded: habitat type (a four level factor), the size of each nest (a continuous variable, calculated as half-width multiplied by height) and species (a two level factor).  
    
\textbf{Case study: Amakihi.} Marques et al. \cite{Marques:2007vm} analyse point transect data on a Hawaiian songbird, the Amakihi (\textit{Hemignathus virens}). The data consist of 1243 observations (after truncation at 82.5m), collected at 41 points between 1992 and 1995, together with three covariates in addition to distance: the observer (a three level factor), minutes after sunrise (continuous) and hours after sunrise (a six level factor).

  
\section*{Results}

\subsection*{Simulation results}

Figure \ref{sim-boxplots} summarizes the estimates of $P_a$ obtained if the candidate model set contains only mixture models (including 1-point mixtures); the numbers below each boxplot are the proportion of times the model selected by AIC was the model which generated the data. Figure S1 shows the distribution of estimates when only K+A models are used, giving a baseline to compare the mixture model results against (Figure S2). Results using the recommended modelling strategy of both mixture and K+A models is shown in Figure S2, and the number of times each model is chosen using the combined modelling strategy is shown in Figure S3.

For Group A, the mixture approach produced unbiased results for scenarios A1 and A3 at all but the lowest sample size; even for the $n=30$ scenarios the bias was small, despite the correct 2-point mixture model being selected only 46-60\% of the time (Figure \ref{sim-boxplots} -- the half normal model was selected the remainder of the time).  The K+A approach also performed well (Figure S1). Unsurprisingly, therefore, the combined approach performed well (Figure S2); what was a little surprising was that the correct model was only selected 60-76\% of the time at the highest sample sizes for scenario A1, with the hazard-rate K+A model selected the remainder (Figure S3). Scenarios A2 and A4 showed positive bias at smaller sample sizes under the mixture approach; bias reduced substantially by 480 observations, where a large proportion of the selected models were 2-point mixtures. Unlike scenarios A1 and A3, the detection functions in scenarios A2 and A4 were evidently not well approximated by a half-normal, and hence at lower sample sizes where the two point mixture tended not to be selected, the results were biased. The K+A approach did not fare well with these scenarios, showing strong positive bias even at the largest sample sizes. In combination, the mixture models were chosen over K+A models at larger sample sizes, and so the combined modelling approach produced much better results than K+A alone.  

As expected, results were worse for the point transect scenarios of Group B. Estimates from the mixture approach were biased at low sample sizes for B1, when the two-point model was rarely selected, but were unbiased given 120 observations and greater. Estimates for B3 were unbiased.  For B2 and B4, results were positively biased at small sample sizes, just as with A2 and A4, but unlike the line transect scenarios the bias did not disappear even at the largest sample size. This is unsurprising given the very small number of detections coming from the less detectable mixture component (see Figure \ref{sim-detfcts} -- the marginal pdf is almost identical to that of the easier to detect mixture component). Bias was generally worse with the K+A approach (Figure S1), and the combined approach (Figure S2) produced marginally better results than K+A alone; for scenarios B1 and B3 the combined results were much better than K+A alone. 

Group C were the 3-point mixture scenarios.  For C1, results were similar to A2 -- unsurprising, given the similarity in detection functions.  A 3-point mixture model was almost never chosen by AIC (Figure \ref{sim-boxplots}).  For C2, estimates were surprisingly good, even when the 3-point mixture was not the selected model, at lower sample sizes.  Evidently, the function is well approximated by a 2-point mixture, although at larger sample sizes ($n=480$ and above), the 3-point model is preferred by AIC. In both cases, the K+A results were worse (Figure S1), although they were not far from unbiased for C2.  In the combined results, the mixture models were chosen most (52-68\%) of the time for model C1, while for C2 the mixture models were chosen less often (15-60\% of the time); despite this, the results were just as good as those using mixtures alone (Figure S2).

We first address the results of the Group D simulations when covariates were available for inclusion in candidate models. Results for D1 were positively biased at lower sample sizes, but less so as the sample size increased, and almost unbiased by 120 observations, where the correct model was selected most of the time (Figure \ref{sim-boxplots}).  Results for D2 were close to unbiased at all sample sizes. Estimates from the K+A models were positively biased at almost all sample sizes for D1, and almost unbiased for D2 (Figure S1).

When covariate information is not available for fitting the model, the mixture model detection functions still performed well, showing that when covariates are not available mixture components can compensate, though not through using additional components (see Figure S3, 3-point mixtures are never AIC-best models).  For the K+A models without covariates, performance was also similar to that from the covariate models, indicating that the flexibility provided by the series adjustment can compensate for lack of covariate information in that framework.  However, results were still slighlty biased even at large sample sizes (Figure S1).  As might be expected, bias was less when both approaches were combined (Figure S2).

The Group E results were encouraging.  Although the mixture formulation was biased even at large sample sizes, the bias was always small (Figure \ref{sim-boxplots}), and generally no worse than that under the K+A formulation, which also showed a small bias (Figure S1). We had anticipated good performance of the mixture models for scenario E1, since the detection function shape is not far from half-normal; however it was not obvious that performance would be good for E2, where the marginal shape cannot be approximated well by a mixture of half-normal functions.  The combined strategy was no worse than either formulation alone in terms of bias.  


\subsection*{Case studies results}

\textbf{British Columbia marine mammals.} Results are summarised in Table \ref{williams-pike-table} and detection functions for the AIC-best models are shown in Figure \ref{williams-detfcts}. In each case mixture models were two component models.  For harbour seal, the mixture model had a lower AIC than for the K+A model reported in Williams and Thomas \cite{Williams:2007tc}. The $\hat{P}_a$ is approximately 20\% lower, implying that the previous estimate of $\hat{N}$ may have been an overestimate.  For harbour porpoise, the mixture model AIC is almost 1.5 points higher than the K+A model, which was a hazard-rate with no adjustments.  Hence, the model likelihoods are very similar, but the penalty due to the 2-point mixture having an additional parameter prevents it from being selected.  The $\hat{P}_a$ from the two models are very close.  Lastly, for humpback whales, the mixture model AIC is almost 3 points higher than the K+A model -- however, one advantage of the mixture model is that the fitted function is monotone (Figure \ref{williams-detfcts}) while the K+A function is not (Figure \ref{fig1}).  Again, the estimated $\hat{P}_a$s are very similar.

\textbf{Long-finned pilot whales.} A mixture model detection function was fitted with each covariate, as well as a model with no covariates. The best model by AIC score (Table \ref{williams-pike-table}) was a 2-point mixture with Beaufort sea state included as a continuous covariate. Figure \ref{danpike-detfct} shows the average detection function (in the sense that a detection function was evaluated over the range $(0,w)$ for each covariate combination and was then averaged point-wise) and the marginal detection function with the quartiles of Beaufort sea state. None of the non-monotonic behaviour seen in Figure \ref{fig1} can occur when a mixture is used.

\textbf{Wood ants.} All combinations of main effects were fitted (Table \ref{williams-pike-table}), and the best model by AIC was a 2-point mixture with nest size and habitat as covariates (Figure S4). This model had an AIC that was considerably (6 points) lower than the AIC-best K+A model, a hazard-rate with the same covariates.  $\hat{P}_a$ is about 10\% lower when estimated using the mixture model.

\textbf{Amakihi.} The AIC-best mixture model was a two point mixture with observer and minutes after sunrise as covariates (Figure S5), closely followed by the model with only observer as a covariate (Table \ref{williams-pike-table}). In this case a hazard-rate with observer and minutes after sunrise as covariates performed better than mixtures in AIC terms, although by less than 1 AIC point. The difference in $\hat{P}_a$ between these two models is about $15\%$.  It is encouraging that there is such a small difference in AIC, and that covariate mixture models were selected over mixture models without covariates, despite the large number of parameters that such models entail.


\section*{Discussion}

We have investigated and demonstrated the utility of detection functions constructed from mixtures of half-normal functions in both line and point transect distance sampling. We also show that covariates can be readily included in such models. Further, these mixture detection functions can be simply ``dropped into'' other extensions of conventional distance sampling such as: methods for dealing with incomplete detection at zero distance \cite{Laake:2004tz, Laake:2011vm} (for these models, there is an additional mark-recapture component to the likelihood, where mixture models could also be used, as in \cite{Pledger:2000tc, Dorazio:2003uf, Pledger:2005wy, Morgan:2008wy}) or spatial models for distance sampling data \cite{Hedley:2004et, Miller:2013us}.

We have shown that the mixture models perform well on both simulated and real data where traditional methods produce suboptimal results. In many cases the proposed model outperformed K+A models in AIC terms, which is surprising given that the K+A formulation is designed to produce parsimonious and realistic fits, and that the mixture models in question often had more parameters. In particular mixture model detection functions appear useful when dealing with line transect data that has a spike in detection probability at small distances, though we note that it is better to avoid collecting such data in the first place, where possible \cite{Buckland:2001vm}.  Also, other non-detection-related factors can cause a spike, such as rounding of measurements or responsive animal movement, and if present in the data these should be dealt with using other analysis strategies or field methods \cite{Buckland:2001vm}.  For line transect surveys, unbiased estimation of $P_a$ was possible even for very spiked detection functions, so long as the sample size of observations was large (Scenarios A2 and A4).  By contrast, estimates remained badly biased at all sample sizes for the equivalent point transect scenarios (B2 and B4). For such surveys, where such a small proportion of the data comes from the closer distances, then perhaps the only effective solution is to constrain the fit, for example using a Bayesian approach with strong priors on the detection function parameters.

We note that in our case studies, a larger coefficient of variation was reported with mixtures than with half-normal K+A models but mixtures seemed to have lower CVs than hazard-rate K+A models (in the line transect case, ignoring non-monotonic K+A models; see Table \ref{williams-pike-table}). This can be explained by considering the flexibility of the detection function. A half-normal detection function is relatively inflexible so uncertainty it low. However, for a hazard-rate model the shoulder can vary from very small (spiked) to very large (depending on the shape parameter), so the uncertainty in this more flexible model is larger. Mixtures of half-normals lie somewhere in between these two options (summing smaller variances). 

Simulations show that small sample sizes do not support the use of mixture models with a high number of components, even when the data were generated from such a model. We avoid poorly fitting models of this sort by using both K+A and mixture detection functions and selecting the best between them (comparing Fig. \ref{sim-boxplots} with Figure S1). This integrated approach is builds upon current model selection procedures for a detection function analysis -- currently selection is made between different K+A formulations and number of adjustment terms using AIC; mixture models simply add another alternative detection function where rather than adjustment terms, mixture components are selected. So existing key-only models are special cases of the mixture detection functions.

In simulation we observed that 3-point mixture did not act as good surrogates for missing covariate information; 2-point mixtures were generally chosen by AIC as good models (however these models were useful). In our case studies, 2-point mixtures consistently provided the best fit. Only examination of further data will show whether 3-point and higher mixtures can be supported, however we note that when the K+A series formulation is used, detection functions with 5 or more parameters are rarely selected by AIC (a 3-point mixture with no covariates requires 5 parameters).

We have compared the new mixture approach for modelling detection functions with the most widely used alternative, K+A. However, other approaches exist, for example nonparametric and semiparametric kernel estimators (see Eidous \cite{Eidous:2011} and references therein).  So far as we are aware, all current alternatives fail some of the criteria given in the introduction -- for example, the kernel functions can be non-monotonic. Giammarino \& Quatto \cite{Giammarino:2014eg} have proposed a ``mixture model'' detection function -- their model takes a rather different form to the mixtures we describe here (simply $\exp\left( -x^2/(2\sigma^2)) - x/\tau\right)$), though their results indicate there is little difference between their model and K+A approaches.

The mixture component used here was a half-normal, but other component functions may prove useful.  In particular, a mixture of hazard-rate functions with different shape and/or scale parameters for each component may be better at fitting detection functions with a wide shoulder, a steep drop-off and then a second plateau in detectability (see E2 in Figure \ref{sim-detfcts}, which was generated from a mixture of two hazard-rate functions).  Further, a mixture of a half-normal (or hazard-rate) and a uniform kernel may proove useful -- this would have only two (or three) parameters, and hence may be more competitive (in AIC terms) with K+A models.

Another potentially useful extension is continuous mixtures of the form
\begin{equation*}
g(x) = \int_\mathbb{R} \varphi(\kappa) g_\kappa(x,\mathbf{Z}; \theta, \kappa) \text{d}\kappa
\end{equation*}
where $\varphi(\kappa)$ is a weighting function that controls the mixing of $g_\kappa$. Provided that an appropriate function can be chosen for $\varphi$, more flexible models could be used whilst keeping the number of parameters low. In addition, a combination of both finite and continuous mixtures could be used, echoing the work in capture-recapture \cite{Morgan:2008wy}.

Mixture model detection functions based on half-normal components are available as an R package, mmds, which is available on CRAN. These models will be added to the next version of the Distance for Windows software and the R package Distance.

\section*{Supporting Information}

\textbf{Appendix S1 Optimization details} (PDF)

\textbf{Appendix S2 Simulation parameters} (PDF)

\textbf{Text S1 Derivatives of the likelihood} (PDF)

\textbf{Text S2 Variance estimation for mixture model detection functions} (PDF)

\textbf{Figure S1 Simulation results: boxplots of the estimated average detection probabilities, $P_a$, for the best K+A model (by AIC score). Grey lines indicate the true value of the average detection probability.} (PDF)

\textbf{Figure S2 Simulation results: boxplots of the estimated average detection probabilities, $P_a$, for the best model (by AIC score) for both mixture and K+A models. In each case the best overall model was selected, reflecting the modelling approach undertaken in practice. Grey lines indicate the true value of the average detection probability. Numbers underneath each boxplot give the proportion of AIC best models that were of the same form as the model that the data was simulated from (e.g., in scenario D1, the proportion of AIC best models that were 2-point mixtures that included the covariate in the model). Numbers above each model give the proportion of times that the AIC best model was a 2- or 3-point mixture model.} (PDF)

\textbf{Figure S3 Simulation results: stacked bar charts showing the number of models selected by AIC that fall into the given model classes. Layout is as in Figure S2. ``hn'' is a half-normal detection function (i.e. 1-point mixture) and ``hr'' is a hazard-rate detection function (no adjustments). K+A indicates a key function plus adjustment term model where ``cos'' is cosine and ``poly'' are simple polynomial adjustments. MMDS is a mixture model with 2 or 3 components (``2-pt'' or ``3-pt'', respectively). ``(cov)'' indicates that covariates were included in the model.} (PDF)

\textbf{Figure S4 Plot of the detection functions for the AIC best model for the ants data set (2-point mixture with nest size and habitat as covariates). The first panel shows the average detection function (dashed lines are the two mixture components of the detection function, averaged over covariate values). The second and third panels show the quartiles of nest size and the levels of habitat type respectively.}

\textbf{Figure S5 Plots of the (AIC) best mixture model for the Amakihi data: a 2-point mixture with observer and minutes after sunrise as covariates. Top row: detection function averaged over covariates (dashed lines are each mixture component averaged over covariates), marginal detection function showing the levels of observer (averaged over the values of minutes after sunrise) and marginal detection function for minutes after sunrise ranging between 0 and 300 minutes (averaged over the levels of observer), as in Marques et al (2007) \cite{Marques:2007vm}. Bottom row: pdf of distances averaged over the covariate values.}


\section*{Acknowledgements}

DLM acknowledges the UK Engineering and Physical Sciences Research Council for financial support during his PhD, and Simon Wood for useful discussions.  Both authors thank David Borchers, who suggested the parametrisation for the mixture proportions (Appendix S1) and Tiago Marques for helpful comments on an earlier draft. The authors also wish to thank Raincoast Conservation Foundation and Rob Williams for allowing the use of perpendicular sightings distance data previously reported in \cite{Williams:2007tc}; Daniel Pike, G\'{i}sli Vikingsson and Bjarni Mikkelsen at the Marine Research Institute, Iceland for the long-finned pilot whales data; Kerry Borkin for the wood ant data and Steven Fancy for the use of the Amakihi data.

%\section*{References}
\bibliography{dsmixtures}

\section*{Tables}

\begin{table}[!ht]
\caption{
{\bf Comparison of case study analysis results.}}
\centering
\begin{tabular}{| c | c | c | c | c | c |}
\hline
{\bf Species} & {\bf Model} & {\bf $\Delta$AIC} & $\hat{P_a}$ & {\bf $\% CV \hat{P_a}$} & {\bf K-S $p$}\\
\hline
Harbour seal (in water) & Hn + $\cos(2)$ & 1.19 & 0.425 & 7.55 & 0.52\\
\hline
 & Hn 2-pt  & 0 & 0.335 & 15.38 & 0.94\\
\hline
Harbour porpoise& Hr  & 0 & 0.212 & 32.0 & 0.99\\
\hline
 & Hn 2-pt & 1.43 & 0.254 & 18.18 & 0.99\\
\hline
Humpback whale & Hn + $\cos(2)$ & 0 & 0.386 & 12.64 & 0.67 \\
\hline
 & Hn 2-pt & 2.88 & 0.381 & 18.48 & 0.64 \\
\hline
Long-finned pilot whales  & Hn + $\cos(2)$ BSS (cont.) & 1.94 & 0.452 & 8.69 & 0.48\\ % mrds
\hline
& Hn 2-pt          &  13.86  &  0.295  &  17.17  &  0.95 \\
\hline
 & Hn 2-pt BSS5         &  0.29   &  0.208  &  28.84  &  0.82 \\
 \hline
 & Hn 2-pt  BSS2        &  0.43  &  0.211  &  23.39  &  0.95 \\
 \hline
 & Hn 2-pt  BSS3        &  11.71 &  0.270  &  17.46  &  0.99 \\
 \hline
 & Hn 2-pt  BSS (cont.) & 0  &  0.216  &  24.17  &  0.67 \\
 \hline
Wood ants & Hr nest.size + habitat & 6.29 & 0.195  & 21.72 & 0.89\\ % mrds result
\hline
 & Hn 2-pt  None                                                     &  17.34 &  0.184  &  15.46  &  0.96 \\
 \hline
 & Hn 2-pt habitat                                          &  14     &  0.188  &  14.85  &  0.97 \\
 \hline
 & Hn 2-pt species                                          &  19.32  &  0.184  &  15.48  &  0.94 \\
 \hline
 & Hn 2-pt nest.size                                        &  4.37   &  0.214  &  15.19  &  0.76 \\
 \hline
 & Hn 2-pt habitat + species                       &  15.96  &  0.186  &  14.94  &  0.99 \\
 \hline
 & Hn 2-pt habitat + nest.size                     &  0      &  0.179  &  17.55  &  0.72 \\
 \hline
 & Hn 2-pt nest.size + species                     &  4.65   &  0.210  &  15.84  &  0.77 \\
 \hline
 & Hn 2-pt nest.size + species + habitat  &  1.81   &  0.178  &  18.09  &  0.83 \\
\hline
Amakihi  & Hr obs + mas & 0 &  0.319 & 5.11 & 0.08\\ % mrds
\hline
 & Hn 2-pt None                                    &  28.1   &  0.283  &  6.21  &  0.12 \\
\hline
 & Hn 2-pt obs                            &  1.31   &  0.279  &  5.86  &  0.04 \\
\hline
 & Hn 2-pt has                            &  29.81  &  0.282  &  6.95  &  0.33 \\
\hline
 & Hn 2-pt mas                            &  27.73  &  0.284  &  6.52  &  0.31 \\
\hline
 & Hn 2-pt obs+has               &  5.15   &  0.283  &  6.21  &  0.23 \\
\hline
 & Hn 2-pt obs+mas               &  0.69   &  0.279  &  6.1  &  0.14 \\
\hline
 & Hn 2-pt mas+has               &  31.79  &  0.282  &  6.97  &  0.43 \\
\hline
 & Hn 2-pt mas+has+obs  &  7.12  &  0.282  &  6.33  &  0.35 \\
\hline
\end{tabular}
\begin{flushleft}Comparison of results from Williams and Thomas \cite{Williams:2007tc}, Pike et al. \cite{Pike:2003ug}, Borkin et al. \cite{Borkin:2012vj} and Marques et al. \cite{Marques:2007vm} with results from fitting mixture model detection functions. In each case the first line for each data set is the model from the original article. Mixture model components were selected by AIC ($\Delta$AIC from best model is listed). In the table ``(cont.)'' denotes that the covariate was included in the model as continuous, otherwise covariates entered the model as factors (BBSn indicates Beaufort sea state with $n$ factors). $\cos(x)$ indicates a Cosine adjustment of order $x$. K-S $p$ is the $p$-value from a Kolmogorov-Smirnov goodness-of-fit test.
\end{flushleft}
\label{williams-pike-table}
\end{table}




\section*{Figure Legends}

\begin{figure}[!ht]
\centering
%\includegraphics[width=\textwidth]{Figure1.eps}
\caption{
{\bf Two examples of detection functions that are not monotone, fitted using conventional key function plus adjustment methods in the software Distance.} The left panel shows data from humpback whale: a half-normal detection function with cosine adjustments was selected by AIC \cite{Williams:2007tc} but even with constraints in place the detection function is non-monotonic, with a small secondary peak at approx. 1500m. The second and third panels show data and models fitted to long-finned pilot whale where a half-normal detection function was selected with cosine adjustments and Beaufort sea state as a covariate \cite{Pike:2003ug}. Due to the inclusion of covariates, no monotonicity constraints could be employed.  The middle panel shows the detection function averaged over the covariate values and the right panel the marginal detection function for 25th, 50th and 75th quantiles of the Beaufort sea state covariate; non-monotonicity occurs at approx. 2500m.
}
\label{fig1}
\end{figure}


\begin{figure}[!ht]
\centering
%\includegraphics[width=\textwidth]{Figure2.eps}
\caption{
{\bf Plots of the models used in the simulation.} Group A (top row): detection functions for four line transect senarios with no covariates (solid lines) and their constituent mixture components (dashed lines). Group B (second row): pdfs for four point transect simulations with no covariates (solid lines), with associates component pdfs (dashed lines), rescaled so the area under each curve is one; the detection functions are as in the top row. Group C (third row): two 3-point mixture scenarios for non-covariate line transect data. Group D (fourth row): two covariate model scenarios, the first two panels are for a binary covariate scenario, the second two for a continuous covariate scenario; first panels in each pair show the detection function averaged over the covariates (along with the mixture components, similarly averaged) and the second panels show marginal detection functions with the levels (or quartiles) of the detection function.  Group E (fifth row): exponential power series model and a 2-point mixture of hazard-rate function (see Appendix S2 for formulation) for two line transect scenarios.
}
\label{sim-detfcts}
\end{figure}

\begin{figure}[!ht]
\centering
%\includegraphics[width=\textwidth]{Figure3.eps}
\caption{
{\bf Simulation results: boxplots of the estimated average detection probabilities, $P_a$, for the best mixture model (by AIC score).} Layout is as in Figure \ref{sim-detfcts}. Grey lines indicate the true value of the average detection probability. Numbers underneath each boxplot give the proportion of AIC best models that were of the same form as the model that the data was simulated from (e.g., Scenario D1 the proportion of AIC best models that were 2-point mixtures that included the covariate in the model).
}
\label{sim-boxplots}
\end{figure}

\begin{figure}[!ht]
\centering
%\includegraphics[width=\textwidth]{Figure4.eps}
\caption{
{\bf Plots of the mixture model detection functions fit to the British Columbia marine mammal data.} In each case the best mixture model by AIC was a 2-point mixture. Dashed lines show the mixture components.
}
\label{williams-detfcts}
\end{figure}

\begin{figure}[!ht]
\centering
%\includegraphics[width=\textwidth]{Figure5.eps}
\caption{
{\bf The (AIC) best model for the long-finned pilot whale data: a 2-point mixture model detection function with Beaufort sea state as a continuous covariate.} Left: the average detection function (detection function evaluated over the range $(0,w)$ for each covariate combination and was then averaged point-wise) with components as dashed lines. Right: the marginal detection function with the quantiles (25\%, 50\% and 75\%) of the Beaufort sea state.
}
\label{danpike-detfct}
\end{figure}






\end{document}
